{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "<img src=\"https://africa.dlnlp.ai/simba/images/VoC_simba\" alt=\"VoC Simba Models Logo\">\n",
        "\n",
        "\n",
        "[![EMNLP 2025 Paper](https://img.shields.io/badge/EMNLP_2025-Paper-B31B1B?style=for-the-badge&logo=arxiv&logoColor=B31B1B&labelColor=FFCDD2)](https://aclanthology.org/2025.emnlp-main.559/)\n",
        "[![Official Website](https://img.shields.io/badge/Official-Website-2EA44F?style=for-the-badge&logo=googlechrome&logoColor=2EA44F&labelColor=C8E6C9)](https://africa.dlnlp.ai/simba/)\n",
        "[![SimbaBench](https://img.shields.io/badge/SimbaBench-Benchmark-8A2BE2?style=for-the-badge&logo=googlecharts&logoColor=8A2BE2&labelColor=E1BEE7)](#simbabench)\n",
        "[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-FFD21E?style=for-the-badge&logoColor=black&labelColor=FFF9C4)](https://huggingface.co/collections/UBC-NLP/simba-speech-series)\n",
        "[![YouTube Video](https://img.shields.io/badge/YouTube-Video-FF0000?style=for-the-badge&logo=youtube&logoColor=FF0000&labelColor=FFCCBC)](#demo)\n",
        "\n",
        "</div>\n",
        "\n",
        "## *Bridging the Digital Divide for African AI*\n",
        "\n",
        "**Voice of a Continent** is a comprehensive open-source ecosystem designed to bring African languages to the forefront of artificial intelligence. By providing a unified suite of benchmarking tools and state-of-the-art models, we ensure that the future of speech technology is inclusive, representative, and accessible to over a billion people.\n",
        "\n",
        "## Best-in-Class Multilingual Models\n",
        "\n",
        "Introduced in our EMNLP 2025 paper *[Voice of a Continent](https://aclanthology.org/2025.emnlp-main.559/)*, the **Simba Series** represents the current state-of-the-art for African speech AI.\n",
        "\n",
        "- **Unified Suite:** Models optimized for African languages.\n",
        "- **Superior Accuracy:** Outperforms generic multilingual models by leveraging SimbaBench's high-quality, domain-diverse datasets.\n",
        "- **Multitask Capability:** Designed for high performance in ASR (Automatic Speech Recognition) and TTS (Text-to-Speech).\n",
        "- **Inclusion-First:** Specifically built to mitigate the \"digital divide\" by empowering speakers of underrepresented languages.\n",
        "\n",
        "The **Simba** family consists of state-of-the-art models fine-tuned using SimbaBench. These models achieve superior performance by leveraging dataset quality, domain diversity, and language family relationships.\n",
        "\n",
        "### üó£Ô∏è‚úçÔ∏è Simba-ASR\n",
        "> **The New Standard for African Speech-to-Text**\n",
        "\n",
        "**üéØ Task** `Automatic Speech Recognition` ‚Äî Powering high-accuracy transcription across the continent.\n",
        "\n",
        "**üåç Language Coverage (43 African languages)**\n",
        ">  **Amharic** (`amh`), **Arabic** (`ara`), **Asante Twi** (`asanti`), **Bambara** (`bam`), **Baoul√©** (`bau`), **Bemba** (`bem`), **Ewe** (`ewe`), **Fanti** (`fat`), **Fon** (`fon`), **French** (`fra`), **Ganda** (`lug`), **Hausa** (`hau`), **Igbo** (`ibo`), **Kabiye** (`kab`), **Kinyarwanda** (`kin`), **Kongo** (`kon`), **Lingala** (`lin`), **Luba-Katanga** (`lub`), **Luo** (`luo`), **Malagasy** (`mlg`), **Mossi** (`mos`), **Northern Sotho** (`nso`), **Nyanja** (`nya`), **Oromo** (`orm`), **Portuguese** (`por`), **Shona** (`sna`), **Somali** (`som`), **Southern Sotho** (`sot`), **Swahili** (`swa`), **Swati** (`ssw`), **Tigrinya** (`tir`), **Tsonga** (`tso`), **Tswana** (`tsn`), **Twi** (`twi`), **Umbundu** (`umb`), **Venda** (`ven`), **Wolof** (`wol`), **Xhosa** (`xho`), **Yoruba** (`yor`), **Zulu** (`zul`), **Tamazight** (`tzm`), **Sango** (`sag`), **Dinka** (`din`).\n",
        "\n",
        "**üèóÔ∏è Base Architectures**\n",
        "\n",
        "  -  **Simba-S** (SeamlessM4T-v2-MT) ‚Äî *Top Performer*\n",
        "  - **Simba-W** (Whisper-v3-large)\n",
        "  - **Simba-X** (Wav2Vec2-XLS-R-2b)\n",
        "  - **Simba-M** (MMS-1b-all)\n",
        "  - **Simba-H** (AfriHuBERT)\n",
        "      \n",
        "| **ASR Models**   | **Architecture**  | **#Parameters** | **ü§ó Hugging Face Model Card** | **Status** |\n",
        "|---------|:------------------:| :------------------:| :------------------:|:------------------:|    \n",
        "| üî•**Simba-S**üî•|    SeamlessM4T-v2  |  2.3B | ü§ó [https://huggingface.co/UBC-NLP/Simba-S](https://huggingface.co/UBC-NLP/Simba-S) | ‚úÖ Released |\n",
        "| üî•**Simba-W**üî•|    Whisper         |  1.5B | ü§ó [https://huggingface.co/UBC-NLP/Simba-W](https://huggingface.co/UBC-NLP/Simba-W) | ‚úÖ Released |\n",
        "| üî•**Simba-X**üî•|    Wav2Vec2        |  1B | ü§ó [https://huggingface.co/UBC-NLP/Simba-X](https://huggingface.co/UBC-NLP/Simba-X) | ‚úÖ Released |   \n",
        "| üî•**Simba-M**üî•|    MMS             |  1B | ü§ó [https://huggingface.co/UBC-NLP/Simba-M](https://huggingface.co/UBC-NLP/Simba-M) | ‚úÖ Released |   \n",
        "| üî•**Simba-H**üî•|    HuBERT          |  94M | ü§ó [https://huggingface.co/UBC-NLP/Simba-H](https://huggingface.co/UBC-NLP/Simba-H) | ‚úÖ Released |   \n",
        "\n",
        "* **Simba-S** (based on SeamlessM4T-v2-MT) emerged as the best-performing ASR model overall.\n"
      ],
      "metadata": {
        "id": "Lfwl1HNj-Q60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and load requirments"
      ],
      "metadata": {
        "id": "CEHPJiqEBZV9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "J6vizC-WH76Q"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers datasets  huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2TCioOQI2OY"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the model"
      ],
      "metadata": {
        "id": "dI5gXpsAklUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Login with YOUR token (get it from https://huggingface.co/settings/tokens)\n",
        "login(token=\"hf_xxxxxxx\")  # ‚Üê PASTE YOUR TOKEN HERE\n",
        "\n",
        "# Load Simba model for ASR\n",
        "asr_pipeline = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"UBC-NLP/Simba-S\" #Simba mdoels `UBC-NLP/Simba-S`, `UBC-NLP/Simba-W`, `UBC-NLP/Simba-X`, `UBC-NLP/Simba-H`, `UBC-NLP/Simba-M`\n",
        ")"
      ],
      "metadata": {
        "id": "nLwwqZGFkz6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only for  `UBC-NLP/Simba-M`\n",
        "asr_pipeline.model.load_adapter(\"multilingual_african\")\n"
      ],
      "metadata": {
        "id": "XNgu4mJWlHfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcribe audio file"
      ],
      "metadata": {
        "id": "yTe0ozGpBuYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Direct from the audio file\n",
        "result = asr_pipeline(\"https://africa.dlnlp.ai/simba/audio/afr_Lwazi_afr_test_idx3889.wav\")\n",
        "\n",
        "print(f\"Transcription: {result['text']}\")"
      ],
      "metadata": {
        "id": "7kRRwu_SlY2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb-a1Bf-mDg-"
      },
      "outputs": [],
      "source": [
        "########### Resampling and loading from array\n",
        "# Load and resample\n",
        "audio, orig_freq =  torchaudio.load(\"https://africa.dlnlp.ai/simba/audio/afr_Lwazi_afr_test_idx3889.wav\")\n",
        "audio =  torchaudio.functional.resample(audio, orig_freq=orig_freq, new_freq=16_000) # must be a 16 kHz waveform array\n",
        "# Now you have your audio array!\n",
        "print(f\"Shape: {audio.shape}\")\n",
        "print(f\"Type: {type(audio)}\")\n",
        "# Get 1D array (if mono or convert to mono)\n",
        "audio_array = audio.mean(dim=0).numpy()  # Average stereo to mono\n",
        "\n",
        "# Process the audio - need to pass both the array and sampling rate\n",
        "result = asr_pipeline({\n",
        "    \"array\": audio_array,\n",
        "    \"sampling_rate\": 16_000\n",
        "})\n",
        "\n",
        "print(f\"Transcription: {result['text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hv7BS1qdcTcw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
